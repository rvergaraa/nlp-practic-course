{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Práctica de NLP: De Cero a Embeddings\n",
    "\n",
    "En esta clase práctica aplicaremos los conceptos de procesamiento de texto, vectorización y embeddings utilizando SpaCy y Scikit-Learn.\n",
    "\n",
    "**Objetivos:**\n",
    "1.  Preprocesar texto crudo.\n",
    "2.  Convertir texto a vectores (TF-IDF).\n",
    "3.  Encontrar documentos similares.\n",
    "4.  Explorar el significado semántico con Embeddings.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración Inicial\n",
    "Ejecuta la siguiente celda para descargar los modelos necesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download es_core_news_sm\n",
    "!python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import es_core_news_sm\n",
    "import es_core_news_md\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a8a97b",
   "metadata": {},
   "source": [
    "## Ejercicios Adicionales: Práctica Detallada\n",
    "\n",
    "Vamos a profundizar antes de pasar a la vectorización. Realiza los siguientes mini-ejercicios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b739fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_ejercicio = \"\"\"\n",
    "El procesamiento de lenguaje natural (NLP) es una rama de la inteligencia artificial.\n",
    "Ayuda a las computadoras a entender, interpretar y manipular el lenguaje humano.\n",
    "¿Podrá la IA escribir novelas completas algún día?\n",
    "\"\"\"\n",
    "\n",
    "doc_ejercicio = nlp(texto_ejercicio)\n",
    "print(texto_ejercicio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio A: Contar Tokens Reales\n",
    "# Cuenta cuántos tokens hay en el texto EXCLUYENDO puntuación y espacios en blanco.\n",
    "# Pista: Usa token.is_punct y token.is_space\n",
    "\n",
    "def contar_tokens_reales(doc):\n",
    "    contador = 0\n",
    "    # TODO: Tu código aquí\n",
    "    return contador\n",
    "\n",
    "print(f\"Tokens reales: {contar_tokens_reales(doc_ejercicio)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4565f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio B: Extraer Sustantivos\n",
    "# Devuelve una lista con todos los sustantivos (NOUN) del texto.\n",
    "# Pista: Usa token.pos_\n",
    "\n",
    "def extraer_sustantivos(doc):\n",
    "    sustantivos = []\n",
    "    # TODO: Tu código aquí\n",
    "    return sustantivos\n",
    "\n",
    "print(f\"Sustantivos: {extraer_sustantivos(doc_ejercicio)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2477788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio C: Extraer Verbos (Lemas)\n",
    "# Devuelve una lista con los LEMAS de todos los verbos (VERB y AUX) del texto.\n",
    "\n",
    "def extraer_verbos(doc):\n",
    "    verbos_lemas = []\n",
    "    # TODO: Tu código aquí\n",
    "    return verbos_lemas\n",
    "\n",
    "print(f\"Verbos (Lemas): {extraer_verbos(doc_ejercicio)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8681c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio D: Pipeline de Limpieza Avanzado\n",
    "# 1. Tokenizar\n",
    "# 2. Filtrar Stop Words, Puntuación y Espacios\n",
    "# 3. Devolver lista de LEMAS en minúsculas\n",
    "\n",
    "def limpiar_texto_avanzado(texto):\n",
    "    doc = nlp(texto)\n",
    "    tokens_limpios = []\n",
    "    # TODO: Tu código aquí\n",
    "    return tokens_limpios\n",
    "\n",
    "print(f\"Texto Limpio: {limpiar_texto_avanzado(texto_ejercicio)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Limpieza y Vectorización (Nivel Básico)\n",
    "\n",
    "**Tarea:**\n",
    "1.  Carga el modelo pequeño de español (`es_core_news_sm`).\n",
    "2.  Define una función `preprocesar(texto)` que:\n",
    "    *   Tokenice el texto.\n",
    "    *   Elimine Stop Words y puntuación.\n",
    "    *   Devuelva una lista de lemas (en minúsculas).\n",
    "3.  Aplica esta función a la lista de frases proporcionada.\n",
    "4.  Usa `TfidfVectorizer` para convertir las frases procesadas en una matriz numérica.\n",
    "\n",
    "**Pista:** Recuerda que `token.pos_ != 'PUNCT'` ayuda a filtrar puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de prueba\n",
    "frases = [\n",
    "    \"La inteligencia artificial está transformando el mundo.\",\n",
    "    \"El aprendizaje automático es una rama de la inteligencia artificial.\",\n",
    "    \"Me gusta comer pizza con piña los fines de semana.\",\n",
    "    \"Los sistemas de IA aprenden de los datos.\"\n",
    "]\n",
    "\n",
    "# 1. Cargar modelo\n",
    "# nlp = ...\n",
    "\n",
    "# 2. Definir función de preprocesamiento\n",
    "def preprocesar(texto):\n",
    "    # doc = nlp(texto)\n",
    "    # tokens_limpios = [token.lemma_.lower() for token in doc if ...]\n",
    "    # return \" \".join(tokens_limpios)\n",
    "    pass\n",
    "\n",
    "# 3. Procesar las frases\n",
    "# frases_limpias = ...\n",
    "# print(frases_limpias)\n",
    "\n",
    "# 4. Vectorizar con TF-IDF\n",
    "# vectorizer = ...\n",
    "# matriz_tfidf = ...\n",
    "# print(matriz_tfidf.shape)\n",
    "# print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Buscador de Similitud (Nivel Intermedio)\n",
    "\n",
    "**Tarea:**\n",
    "1.  Usa la matriz TF-IDF del ejercicio anterior.\n",
    "2.  Define una nueva frase de consulta (query): `\"La IA cambia la sociedad\"`.\n",
    "3.  Preprocesa y vectoriza esta query usando el *mismo* vectorizador (usa `.transform()`, no `.fit_transform()`).\n",
    "4.  Calcula la **Similitud Coseno** entre la query y todas las frases originales.\n",
    "5.  Muestra cuál es la frase más similar.\n",
    "\n",
    "**Reto Extra (Opcional):** Aplica LSA (`TruncatedSVD`) con 2 componentes para reducir la dimensionalidad antes de comparar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"La IA cambia la sociedad\"\n",
    "\n",
    "# 1. Preprocesar query\n",
    "# query_limpia = ...\n",
    "\n",
    "# 2. Vectorizar query\n",
    "# query_vec = vectorizer.transform([query_limpia])\n",
    "\n",
    "# 3. Calcular similitud\n",
    "# similitudes = cosine_similarity(..., ...)\n",
    "\n",
    "# 4. Mostrar resultados\n",
    "# for i, sim in enumerate(similitudes[0]):\n",
    "#     print(f\"Frase: {frases[i]} | Similitud: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Explorando Significados con Embeddings (Nivel Avanzado)\n",
    "\n",
    "**Tarea:**\n",
    "1.  Carga el modelo mediano (`es_core_news_md`) que sí tiene vectores.\n",
    "2.  Define una lista de palabras: `[\"perro\", \"gato\", \"coche\", \"moto\", \"manzana\", \"banana\", \"ordenador\"]`.\n",
    "3.  Obtén los vectores (embeddings) de cada palabra.\n",
    "4.  Calcula la similitud entre pares de palabras (ej: perro vs gato, perro vs coche).\n",
    "5.  (Visualización) Usa PCA para reducir los vectores a 2 dimensiones y grafícalos en un plano cartesiano.\n",
    "\n",
    "**Pregunta:** ¿Se agrupan las palabras por conceptos (animales, vehículos, comida)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cargar modelo con vectores\n",
    "# nlp_md = ...\n",
    "\n",
    "palabras = [\"perro\", \"gato\", \"coche\", \"moto\", \"manzana\", \"banana\", \"ordenador\"]\n",
    "\n",
    "# 2. Obtener vectores\n",
    "# vectores = [nlp_md(p).vector for p in palabras]\n",
    "\n",
    "# 3. Calcular similitudes (ejemplo)\n",
    "# token1 = nlp_md(\"perro\")\n",
    "# token2 = nlp_md(\"gato\")\n",
    "# print(token1.similarity(token2))\n",
    "\n",
    "# 4. Visualización con PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# vectores_2d = pca.fit_transform(vectores)\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# for i, palabra in enumerate(palabras):\n",
    "#     plt.scatter(vectores_2d[i, 0], vectores_2d[i, 1])\n",
    "#     plt.text(vectores_2d[i, 0]+0.02, vectores_2d[i, 1]+0.02, palabra)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
