# -*- coding: utf-8 -*-
"""Practica_2_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Yxq8nCtQgzxC73Y4Zt3C4Nq85W37AJtk

Descargar modelo para español
"""

!python -m spacy download es_core_news_sm gensim

"""### Importar biblioteca para NLP

Estudiando -> Estudiar
"""

import spacy
import es_core_news_sm
import spacy.lang.es.stop_words

nlp = es_core_news_sm.load()
stop_words = spacy.lang.es.stop_words.STOP_WORDS

"""### Texto ejemplo: Wikipedia - Biologia"""

texto = "La biología es la ciencia natural que estudia todo lo relacionado con la vida, lo orgánico y los procesos biológicos de los seres vivos en diversos campos especializados. "
texto += "La biología se ocupa tanto de la descripción de las características y los comportamientos de los organismos individuales, como de las especies en su conjunto, así como de la reproducción de los seres vivos y de las interacciones entre ellos y el entorno."
texto += "De este modo, trata de estudiar la estructura y la dinámica funcional comunes a todos los seres vivos, con el fin de establecer las leyes generales que rigen la vida orgánica y los principios de ésta."
texto += "La escala de estudio va desde los subcomponentes biofísicos hasta los sistemas complejos, los cuales componen los niveles de la organización biológica."
texto += "La biología moderna se divide en subdisciplinas según los tipos de organismos y la escala en que se los estudia."
texto += "Por ejemplo, la biología molecular estudia de las biomoléculas fundamentales de los organismos, mientras que la biología celular tiene como objeto el análisis de la célula, que es la unidad constitutiva básica de toda la vida."

"""### Aplicar NLP de spAcy y ver que contiene"""

prp_corpus = nlp(texto)

for token in prp_corpus:
  print(token.text, token.lemma_, token.pos_)

def prp_oracion(oracion):
  prp_or = [token.lemma_.lower() for token in oracion if token.text not in stop_words and token.pos_ != "PUNCT" ]
  or_string = ""
  for token in prp_or:
    or_string += token + " "
  return or_string

def prp_doc(text):
  doc = []
  for sent in text.sents:
    doc.append(prp_oracion(sent))
  return doc

doc = prp_doc(prp_corpus)
print(doc)

"""### Importar bibliotecas para machine learning"""

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics.pairwise import cosine_similarity

vectorizer = CountVectorizer() # Bag of Words / One Hot
tfidf = TfidfVectorizer()

X = vectorizer.fit_transform(doc)
Y = tfidf.fit_transform(doc)

"""TF (Frecuencia de término): La frecuencia de una palabra en un documento, normalizada para que no dependa del tamaño del documento.

IDF (Frecuencia inversa de documentos): Mide cuán única es una palabra en todo el corpus:

$$\text{IDF}(t) = \log\left(\frac{N}{1 + \text{DF}(t)}\right)$$
"""

print(vectorizer.get_feature_names_out())
print(X.shape)
print(X)

print(tfidf.get_feature_names_out())
print(Y.shape)
print(Y)

"""Probar con nuevos ejemplos

"""

test_1 = "Algunos desarrollos históricos clave en la ciencia de la biología fueron las leyes de la genética que ayudaron a formular la síntesis evolutiva moderna cuya base es la teoría de la evolución mediante selección natural, el dogma central de la biología molecular, la biogénesis, la teoría celular, la teoría microbiana de la enfermedad y la aplicación de técnicas de la física y la química a nivel celular y molecular, que dieron lugar a la biofísica y bioquímica, respectivamente."
test_2 = "La química es la ciencia que estudia la composición, estructura y propiedades de la materia, así como los cambios que esta experimenta durante las reacciones químicas y su relación con la energía."

prp_1 = nlp(test_1)
prp_2 = nlp(test_2)

doc_test_1 = prp_doc(prp_1)
print(doc_test_1)

doc_test_2 = prp_doc(prp_2)
print(doc_test_2)

x_1 = vectorizer.transform(doc_test_1)
x_2 = vectorizer.transform(doc_test_2)

print(x_1)
print()
print(x_2)

"""Comparar nuevos datos con partes del texto original"""

base = vectorizer.transform([doc[0]])
print(cosine_similarity(base,x_1), cosine_similarity(base,x_2))

"""### TF-IDF"""

x_1 = tfidf.transform(doc_test_1)
x_2 = tfidf.transform(doc_test_2)

print(x_1)
print()
print(x_2)

base = tfidf.transform([doc[0]])
print(cosine_similarity(base,x_1), cosine_similarity(base,x_2))

"""### LSA"""

svd_X = TruncatedSVD(n_components=2)
lsa_X = svd_X.fit_transform(X)
print(lsa_X)

x_1 = svd_X.transform(vectorizer.transform(doc_test_1))
x_2 = svd_X.transform(vectorizer.transform(doc_test_2))
base = svd_X.transform(vectorizer.transform([doc[0]]))
print(cosine_similarity(base,x_1), cosine_similarity(base,x_2))

svd_Y = TruncatedSVD(n_components=5)
lsa_Y = svd_Y.fit_transform(Y)
print(lsa_Y)

y_1 = svd_Y.transform(tfidf.transform(doc_test_1))
y_2 = svd_Y.transform(tfidf.transform(doc_test_2))
base = svd_Y.transform(tfidf.transform([doc[0]]))
print(cosine_similarity(base,y_1), cosine_similarity(base,y_2))

"""### Embeddings"""

!python -m spacy download es_core_news_md

import spacy
import numpy as np
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# 1. Cargar el modelo spaCy con embeddings pre-entrenados
nlp = spacy.load("es_core_news_md")  # Modelo en español con embeddings medianos
print("Modelo cargado:", nlp.meta["name"])

# 2. Obtener embeddings de palabras
words = ["rey", "reina", "hombre", "mujer", "niño", "padre", "madre", "manzana", "plátano"]
word_vectors = {word: nlp(word).vector for word in words}
# Mostrar dimensiones de los embeddings
print("\nDimensión de los embeddings:", len(next(iter(word_vectors.values()))))

# Obtener y mostrar los embeddings
for word, vector in word_vectors.items():
    print(f"Palabra: {word}")
    print(f"Vector: {vector}")
    print(f"Tamaño del vector: {len(vector)}\n")

# 3. Medir similitudes entre palabras
print("\nSimilitud entre palabras:")
for word1, word2 in [("rey", "reina"), ("rey", "manzana"), ("hombre", "mujer"), ("hombre", "rey")]:
    similarity = nlp(word1).similarity(nlp(word2))
    print(f"Similitud entre '{word1}' y '{word2}': {similarity:.4f}")

# 4. Visualizar embeddings con PCA
print("\nVisualizando embeddings...")
pca = PCA(n_components=2)
embeddings_matrix = np.array(list(word_vectors.values()))
reduced_embeddings = pca.fit_transform(embeddings_matrix) # Reduce la dimension de los embeddings
# Graficar palabras en el espacio reducido
plt.figure(figsize=(8, 6))
for word, coords in zip(words, reduced_embeddings):
    plt.scatter(coords[0], coords[1], c="red")
    plt.text(coords[0] + 0.01, coords[1] + 0.01, word, fontsize=12)
plt.title("Visualización de Word Embeddings con PCA (spaCy)")
plt.xlabel("PCA 1")
plt.ylabel("PCA 2")
plt.grid()
plt.show()

# 5. Comparar similitudes entre frases
phrase1 = "el hombre es fuerte"
phrase2 = "la mujer es fuerte"
phrase3 = "la manzana está deliciosa"

print("\nSimilitudes entre frases:")
doc1 = nlp(phrase1)
doc2 = nlp(phrase2)
doc3 = nlp(phrase3)
print(f"'{phrase1}' vs '{phrase2}': {doc1.similarity(doc2):.4f}")
print(f"'{phrase1}' vs '{phrase3}': {doc1.similarity(doc3):.4f}")