{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Pr\u00e1ctica de NLP: Soluciones\n",
    "\n",
    "Este cuaderno contiene las soluciones completas para los ejercicios pr\u00e1cticos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraci\u00f3n Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download es_core_news_sm\n",
    "!python -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import es_core_news_sm\n",
    "import es_core_news_md\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios Adicionales: Pr\u00e1ctica Detallada (Soluci\u00f3n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_ejercicio = \"\"\"\n",
    "El procesamiento de lenguaje natural (NLP) es una rama de la inteligencia artificial.\n",
    "Ayuda a las computadoras a entender, interpretar y manipular el lenguaje humano.\n",
    "\u00bfPodr\u00e1 la IA escribir novelas completas alg\u00fan d\u00eda?\n",
    "\"\"\"\n",
    "\n",
    "doc_ejercicio = nlp(texto_ejercicio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio A: Contar Tokens Reales\n",
    "def contar_tokens_reales(doc):\n",
    "    contador = 0\n",
    "    for token in doc:\n",
    "        if not token.is_punct and not token.is_space:\n",
    "            contador += 1\n",
    "    return contador\n",
    "\n",
    "print(f\"Tokens reales: {contar_tokens_reales(doc_ejercicio)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio B: Extraer Sustantivos\n",
    "def extraer_sustantivos(doc):\n",
    "    sustantivos = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
    "    return sustantivos\n",
    "\n",
    "print(f\"Sustantivos: {extraer_sustantivos(doc_ejercicio)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio C: Extraer Verbos (Lemas)\n",
    "def extraer_verbos(doc):\n",
    "    verbos = [token.lemma_ for token in doc if token.pos_ in [\"VERB\", \"AUX\"]]\n",
    "    return verbos\n",
    "\n",
    "print(f\"Verbos (Lemas): {extraer_verbos(doc_ejercicio)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio D: Pipeline de Limpieza Avanzado\n",
    "def limpiar_texto_avanzado(texto):\n",
    "    doc_local = nlp(texto)\n",
    "    tokens_limpios = [\n",
    "        token.lemma_.lower() \n",
    "        for token in doc_local \n",
    "        if not token.is_stop and not token.is_punct and not token.is_space\n",
    "    ]\n",
    "    return tokens_limpios\n",
    "\n",
    "print(f\"Texto Limpio: {limpiar_texto_avanzado(texto_ejercicio)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Limpieza y Vectorizaci\u00f3n (Soluci\u00f3n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de prueba\n",
    "frases = [\n",
    "    \"La inteligencia artificial est\u00e1 transformando el mundo.\",\n",
    "    \"El aprendizaje autom\u00e1tico es una rama de la inteligencia artificial.\",\n",
    "    \"Me gusta comer pizza con pi\u00f1a los fines de semana.\",\n",
    "    \"Los sistemas de IA aprenden de los datos.\"\n",
    "]\n",
    "\n",
    "# 1. Cargar modelo\n",
    "nlp = es_core_news_sm.load()\n",
    "\n",
    "# 2. Definir funci\u00f3n de preprocesamiento\n",
    "def preprocesar(texto):\n",
    "    doc = nlp(texto)\n",
    "    # Filtrar stopwords y puntuaci\u00f3n, y obtener lemas\n",
    "    tokens_limpios = [\n",
    "        token.lemma_.lower() \n",
    "        for token in doc \n",
    "        if not token.is_stop and token.pos_ != 'PUNCT'\n",
    "    ]\n",
    "    return \" \".join(tokens_limpios)\n",
    "\n",
    "# 3. Procesar las frases\n",
    "frases_limpias = [preprocesar(f) for f in frases]\n",
    "print(\"Frases limpias:\", frases_limpias)\n",
    "\n",
    "# 4. Vectorizar con TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "matriz_tfidf = vectorizer.fit_transform(frases_limpias)\n",
    "\n",
    "print(\"\\nDimensiones de la matriz:\", matriz_tfidf.shape)\n",
    "print(\"Vocabulario:\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Buscador de Similitud (Soluci\u00f3n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"La IA cambia la sociedad\"\n",
    "\n",
    "# 1. Preprocesar query\n",
    "query_limpia = preprocesar(query)\n",
    "print(f\"Query procesada: {query_limpia}\")\n",
    "\n",
    "# 2. Vectorizar query (usando transform, NO fit_transform)\n",
    "query_vec = vectorizer.transform([query_limpia])\n",
    "\n",
    "# 3. Calcular similitud\n",
    "similitudes = cosine_similarity(query_vec, matriz_tfidf)\n",
    "\n",
    "# 4. Mostrar resultados\n",
    "print(\"\\nResultados de similitud:\")\n",
    "for i, sim in enumerate(similitudes[0]):\n",
    "    print(f\"Frase: '{frases[i]}' | Similitud: {sim:.4f}\")\n",
    "\n",
    "idx_max = np.argmax(similitudes)\n",
    "print(f\"\\nLa frase m\u00e1s similar es: '{frases[idx_max]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reto Extra: LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(n_components=2)\n",
    "matriz_lsa = lsa.fit_transform(matriz_tfidf)\n",
    "query_lsa = lsa.transform(query_vec)\n",
    "\n",
    "similitudes_lsa = cosine_similarity(query_lsa, matriz_lsa)\n",
    "print(\"Similitudes con LSA:\", similitudes_lsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Explorando Significados con Embeddings (Soluci\u00f3n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cargar modelo con vectores\n",
    "nlp_md = es_core_news_md.load()\n",
    "\n",
    "palabras = [\"perro\", \"gato\", \"coche\", \"moto\", \"manzana\", \"banana\", \"ordenador\"]\n",
    "\n",
    "# 2. Obtener vectores\n",
    "vectores = [nlp_md(p).vector for p in palabras]\n",
    "vectores = np.array(vectores)\n",
    "\n",
    "# 3. Calcular similitudes (ejemplo)\n",
    "token1 = nlp_md(\"perro\")\n",
    "token2 = nlp_md(\"gato\")\n",
    "print(f\"Similitud perro-gato: {token1.similarity(token2):.4f}\")\n",
    "\n",
    "token3 = nlp_md(\"perro\")\n",
    "token4 = nlp_md(\"coche\")\n",
    "print(f\"Similitud perro-coche: {token3.similarity(token4):.4f}\")\n",
    "\n",
    "# 4. Visualizaci\u00f3n con PCA\n",
    "pca = PCA(n_components=2)\n",
    "vectores_2d = pca.fit_transform(vectores)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(vectores_2d[:, 0], vectores_2d[:, 1], c='red')\n",
    "\n",
    "for i, palabra in enumerate(palabras):\n",
    "    plt.text(vectores_2d[i, 0]+0.02, vectores_2d[i, 1]+0.02, palabra, fontsize=12)\n",
    "\n",
    "plt.title(\"Visualizaci\u00f3n de Embeddings con PCA\")\n",
    "plt.xlabel(\"Componente 1\")\n",
    "plt.ylabel(\"Componente 2\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}