{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Clase Práctica de NLP: Soluciones\n",
                "\n",
                "Este cuaderno contiene las soluciones completas para los ejercicios prácticos.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuración Inicial"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python -m spacy download es_core_news_sm\n",
                "!python -m spacy download es_core_news_md"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import spacy\n",
                "import es_core_news_sm\n",
                "import es_core_news_md\n",
                "import numpy as np\n",
                "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "from sklearn.decomposition import TruncatedSVD\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Ejercicio 1: Limpieza y Vectorización (Solución)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Datos de prueba\n",
                "frases = [\n",
                "    \"La inteligencia artificial está transformando el mundo.\",\n",
                "    \"El aprendizaje automático es una rama de la inteligencia artificial.\",\n",
                "    \"Me gusta comer pizza con piña los fines de semana.\",\n",
                "    \"Los sistemas de IA aprenden de los datos.\"\n",
                "]\n",
                "\n",
                "# 1. Cargar modelo\n",
                "nlp = es_core_news_sm.load()\n",
                "\n",
                "# 2. Definir función de preprocesamiento\n",
                "def preprocesar(texto):\n",
                "    doc = nlp(texto)\n",
                "    # Filtrar stopwords y puntuación, y obtener lemas\n",
                "    tokens_limpios = [\n",
                "        token.lemma_.lower() \n",
                "        for token in doc \n",
                "        if not token.is_stop and token.pos_ != 'PUNCT'\n",
                "    ]\n",
                "    return \" \".join(tokens_limpios)\n",
                "\n",
                "# 3. Procesar las frases\n",
                "frases_limpias = [preprocesar(f) for f in frases]\n",
                "print(\"Frases limpias:\", frases_limpias)\n",
                "\n",
                "# 4. Vectorizar con TF-IDF\n",
                "vectorizer = TfidfVectorizer()\n",
                "matriz_tfidf = vectorizer.fit_transform(frases_limpias)\n",
                "\n",
                "print(\"\\nDimensiones de la matriz:\", matriz_tfidf.shape)\n",
                "print(\"Vocabulario:\", vectorizer.get_feature_names_out())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Ejercicio 2: Buscador de Similitud (Solución)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "query = \"La IA cambia la sociedad\"\n",
                "\n",
                "# 1. Preprocesar query\n",
                "query_limpia = preprocesar(query)\n",
                "print(f\"Query procesada: {query_limpia}\")\n",
                "\n",
                "# 2. Vectorizar query (usando transform, NO fit_transform)\n",
                "query_vec = vectorizer.transform([query_limpia])\n",
                "\n",
                "# 3. Calcular similitud\n",
                "similitudes = cosine_similarity(query_vec, matriz_tfidf)\n",
                "\n",
                "# 4. Mostrar resultados\n",
                "print(\"\\nResultados de similitud:\")\n",
                "for i, sim in enumerate(similitudes[0]):\n",
                "    print(f\"Frase: '{frases[i]}' | Similitud: {sim:.4f}\")\n",
                "\n",
                "idx_max = np.argmax(similitudes)\n",
                "print(f\"\\nLa frase más similar es: '{frases[idx_max]}'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Reto Extra: LSA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lsa = TruncatedSVD(n_components=2)\n",
                "matriz_lsa = lsa.fit_transform(matriz_tfidf)\n",
                "query_lsa = lsa.transform(query_vec)\n",
                "\n",
                "similitudes_lsa = cosine_similarity(query_lsa, matriz_lsa)\n",
                "print(\"Similitudes con LSA:\", similitudes_lsa)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Ejercicio 3: Explorando Significados con Embeddings (Solución)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Cargar modelo con vectores\n",
                "nlp_md = es_core_news_md.load()\n",
                "\n",
                "palabras = [\"perro\", \"gato\", \"coche\", \"moto\", \"manzana\", \"banana\", \"ordenador\"]\n",
                "\n",
                "# 2. Obtener vectores\n",
                "vectores = [nlp_md(p).vector for p in palabras]\n",
                "vectores = np.array(vectores)\n",
                "\n",
                "# 3. Calcular similitudes (ejemplo)\n",
                "token1 = nlp_md(\"perro\")\n",
                "token2 = nlp_md(\"gato\")\n",
                "print(f\"Similitud perro-gato: {token1.similarity(token2):.4f}\")\n",
                "\n",
                "token3 = nlp_md(\"perro\")\n",
                "token4 = nlp_md(\"coche\")\n",
                "print(f\"Similitud perro-coche: {token3.similarity(token4):.4f}\")\n",
                "\n",
                "# 4. Visualización con PCA\n",
                "pca = PCA(n_components=2)\n",
                "vectores_2d = pca.fit_transform(vectores)\n",
                "\n",
                "plt.figure(figsize=(8,6))\n",
                "plt.scatter(vectores_2d[:, 0], vectores_2d[:, 1], c='red')\n",
                "\n",
                "for i, palabra in enumerate(palabras):\n",
                "    plt.text(vectores_2d[i, 0]+0.02, vectores_2d[i, 1]+0.02, palabra, fontsize=12)\n",
                "\n",
                "plt.title(\"Visualización de Embeddings con PCA\")\n",
                "plt.xlabel(\"Componente 1\")\n",
                "plt.ylabel(\"Componente 2\")\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}