{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Soluciones: Limpieza de Texto"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install spacy -q\n",
                "!python -m spacy download es_core_news_sm\n",
                "import spacy\n",
                "import re\n",
                "nlp = spacy.load(\"es_core_news_sm\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Ejercicio 1: Limpiador de Tweets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tweets = [\n",
                "    \"隆Incre铆ble partido! #futbol #ganador @equipo\",\n",
                "    \"No me gust贸 el servicio  @servicio_cliente\",\n",
                "    \"Oferta limitada en http://spam.com #oferta\"\n",
                "]\n",
                "\n",
                "def limpiar_tweet(tweet):\n",
                "    # 1. Quitar hashtags y menciones\n",
                "    tweet = re.sub(r'[#@]\\w+', '', tweet)\n",
                "    \n",
                "    # 2. Quitar URLs\n",
                "    tweet = re.sub(r'http\\S+', '', tweet)\n",
                "    \n",
                "    # 3. Quitar caracteres que no sean palabras (quita emojis y puntuaci贸n extra)\n",
                "    # OJO: Esto es agresivo, tambi茅n quita signos de exclamaci贸n\n",
                "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
                "    \n",
                "    return tweet.strip()\n",
                "\n",
                "print(\"Soluci贸n 1:\")\n",
                "for t in tweets:\n",
                "    print(f\"Original: {t} -> Limpio: {limpiar_tweet(t)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Ejercicio 2: Normalizaci贸n de Productos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "productos = [\"Iphone 12\", \"iPhone 12..\", \"iphone 12\", \"Samsung s21!!\", \"SAMSUNG S21\"]\n",
                "\n",
                "def normalizar_producto(producto):\n",
                "    # 1. Min煤sculas\n",
                "    producto = producto.lower()\n",
                "    # 2. Quitar puntuaci贸n\n",
                "    producto = re.sub(r'[^a-z0-9\\s]', '', producto)\n",
                "    return producto.strip()\n",
                "\n",
                "productos_limpios = set(normalizar_producto(p) for p in productos)\n",
                "print(\"\\nSoluci贸n 2 (Lista 煤nica):\", productos_limpios)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}