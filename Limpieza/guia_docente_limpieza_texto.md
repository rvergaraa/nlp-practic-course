# Gu√≠a Docente: Importancia de la Limpieza de Texto en NLP

**Archivo del Notebook:** `clase_limpieza_texto.ipynb`
**Duraci√≥n Estimada:** 45 - 60 minutos
**Requisitos T√©cnicos:** Python local o Google Colab (CPU es suficiente)

---

## üéØ Objetivos de Aprendizaje
Al finalizar la clase, los estudiantes ser√°n capaces de:
1.  **Identificar** los tipos comunes de "ruido" en datos textuales (HTML, stop words, caracteres especiales).
2.  **Aplicar** t√©cnicas de normalizaci√≥n (lowercasing, eliminaci√≥n de acentos) y limpieza usando `regex` y `spaCy`.
3.  **Comparar** el impacto del preprocesamiento en el tama√±o del vocabulario y la calidad de las features.
4.  **Entender** la diferencia pr√°ctica entre Stemming y Lemmatization.

---

## ‚è±Ô∏è Cronograma de la Clase (Minuto a Minuto)

| Tiempo | Secci√≥n | Descripci√≥n y Puntos Clave |
| :--- | :--- | :--- |
| **00-10** | **1. El Problema del Texto "Sucio"** | - **Contexto**: Mostrar un tweet o comentario real con emojis, errores y hashtags.<br>- **Discusi√≥n**: ¬øPor qu√© es dif√≠cil para una m√°quina entender "HOLA!!!" vs "hola"?<br>- **Concepto**: La maldici√≥n de la dimensionalidad (Vocabulario inflado). |
| **10-25** | **2. La Caja de Herramientas** | - **Regex**: Patrones b√°sicos para eliminar URLs y emails.<br>- **Normalizaci√≥n**: `unicodedata` para quitar tildes.<br>- **Stop Words**: Discutir cu√°ndo quitarlas y cu√°ndo no (ej. "No me gusta" -> quitando "no" queda "gusta"). |
| **25-40** | **3. Demo: El Impacto Real** | - Usar `CountVectorizer` en un corpus peque√±o.<br>- **Caso A (Sucio)**: Mostrar features duplicadas (`[Correr, correr, Corriendo]`).<br>- **Caso B (Limpio)**: Mostrar features unificadas (`[correr]`).<br>- **M√©trica**: Reducci√≥n del tama√±o del vocabulario (ej. de 1000 a 300 tokens). |
| **40-45** | **4. Pipeline con SpaCy** | - Automatizar todo en una funci√≥n `clean_text(text)`.<br>- Uso de `doc.lemma_` para reducci√≥n morfol√≥gica. |
| **45-60** | **5. Ejercicios Pr√°cticos** | - Resolver el notebook `ejercicios_limpieza_texto.ipynb`.<br>- Reto: Limpiar dataset de reviews de Amazon (simulado). |

---

## üõ†Ô∏è Soluci√≥n de Problemas Comunes (Troubleshooting)

1.  **Modelo de SpaCy no encontrado (`es_core_news_sm`)**:
    *   *Causa:* No se ha descargado el modelo.
    *   *Soluci√≥n:* Ejecutar `!python -m spacy download es_core_news_sm`.

2.  **Problemas con Encoding (caracteres raros)**:
    *   *Causa:* Archivos le√≠dos sin `encoding='utf-8'`.
    *   *Soluci√≥n:* Siempre forzar UTF-8 al abrir archivos o strings.

3.  **Lemmatization incorrecta ("fuimos" -> "ir" pero "casas" -> "casas")**:
    *   *Explicaci√≥n:* SpaCy es bueno, pero no perfecto. Depende del contexto (POS Tagging). Si la frase es ambigua, el lema puede fallar.

---

## üí° Sugerencias Pedag√≥gicas
*   **Analog√≠a**: Compara la limpieza de texto con "lavar las verduras antes de cocinar". Puedes cocinar con tierra (ruido), pero el plato final (modelo) sabr√° mal.
*   **Debate**: Pregunta si siempre hay que pasar a min√∫sculas. (Respuesta: No, en NER "Apple" vs "apple" es crucial).
